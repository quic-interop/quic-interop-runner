name: interop
on:
  schedule:
   # Every 12h, at 15 minutes past the hour
   # This makes sure that the cleanup cron job can run first.
  - cron: "15 */12 * * *"

jobs:
  config:
    runs-on: ubuntu-latest
    outputs:
      logname: ${{ steps.set-logname.outputs.logname }}
      starttime: ${{ steps.set-starttime.outputs.starttime }}
      servers: ${{ steps.set-servers.outputs.servers }}
      clients: ${{ steps.set-clients.outputs.clients }}
      images: ${{ steps.set-images.outputs.images }}
    steps:
      - name: Set log name
        id: set-logname
        run: |
          LOGNAME=$(date -u +"%Y-%m-%dT%H:%M")
          echo $LOGNAME
          echo "logname=$LOGNAME" >> $GITHUB_OUTPUT
      - name: Save start time
        id: set-starttime
        run: |
          STARTTIME=$(date +%s)
          echo $STARTTIME
          echo "starttime=$STARTTIME" >> $GITHUB_OUTPUT
      - uses: actions/checkout@v6
      - uses: actions/setup-python@v6
        with:
          python-version: 3.8
      - name: Determine servers
        id: set-servers
        run: |
          SERVERS=$(jq -c 'with_entries(select(.value.role == "server" or .value.role == "both")) | keys_unsorted' implementations.json)
          echo $SERVERS
          echo "servers=$SERVERS" >> $GITHUB_OUTPUT
      - name: Determine clients
        id: set-clients
        run: |
          CLIENTS=$(jq -c 'with_entries(select(.value.role == "client" or .value.role == "both")) | keys_unsorted' implementations.json)
          echo $CLIENTS
          echo "clients=$CLIENTS" >> $GITHUB_OUTPUT
      - name: Determine Docker images
        id: set-images
        run: |
          IMAGES=$(jq -c 'keys_unsorted' implementations.json)
          echo $IMAGES
          echo "images=$IMAGES" >> $GITHUB_OUTPUT
  docker-pull-tools:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        image: [ 'quic-network-simulator', 'quic-interop-iperf-endpoint' ]
    steps:
    - uses: actions/checkout@v6
    - name: Pull
      run: |
        URL="martenseemann/${{ matrix.image }}"
        docker pull $URL
        echo "URL=$URL" >> $GITHUB_ENV
    - name: Docker inspect
      run: docker image inspect $URL
    - name: Save Docker image
      run: |
        docker save $URL | gzip --best > ${{ matrix.image }}.tar.gz
        du -sh ${{ matrix.image }}.tar.gz
    - name: Upload result
      uses: actions/upload-artifact@v6
      with:
        name: images-${{ matrix.image }}
        path: ${{ matrix.image }}.tar.gz
        if-no-files-found: error
  docker-pull-images:
    needs: [ config ]
    runs-on: ubuntu-latest
    strategy:
      matrix:
        image: ${{ fromJson(needs.config.outputs.images) }}
    name: Pull ${{ matrix.image }}
    steps:
      - uses: actions/checkout@v6
      - name: Run docker pull
        run: |
          URL=$(jq -r '.["${{ matrix.image }}"].image' implementations.json)
          echo $URL
          docker pull $URL
          echo "URL=$URL" >> $GITHUB_ENV
      - name: Docker inspect
        run: docker image inspect $URL
      - name: Save Docker image
        run: |
          docker save $URL | gzip --best > ${{ matrix.image }}.tar.gz
          du -sh ${{ matrix.image }}.tar.gz
      - name: Upload result
        uses: actions/upload-artifact@v6
        with:
          name: image-${{ matrix.image }}
          path: ${{ matrix.image }}.tar.gz
          if-no-files-found: error
  tests:
    uses: ./.github/workflows/interop-test.yml
    needs: [ config, docker-pull-tools, docker-pull-images ]
    strategy:
      fail-fast: false
      matrix:
        server: ${{ fromJson(needs.config.outputs.servers) }}
    name: "server: ${{ matrix.server }}"
    with:
      server: ${{ matrix.server }}
      clients: ${{ needs.config.outputs.clients }}
      logname: ${{ needs.config.outputs.logname }}
    secrets: inherit
  aggregate:
    needs: [ config, tests ]
    runs-on: ubuntu-latest
    if: always()
    env:
      LOGNAME: ${{ needs.config.outputs.logname }}
    steps:
      - uses: actions/checkout@v6
      - uses: actions/setup-python@v6
        with:
          python-version: 3.8
      - name: Download results
        uses: actions/download-artifact@v7
        with:
          pattern: results-*
      - name: Aggregate results
        run: |
          mv results-*/*.json .
          python .github/workflows/aggregate.py \
            --start-time ${{ needs.config.outputs.starttime }} \
            --server ${{ join(fromJson(needs.config.outputs.servers), ',') }} \
            --client ${{ join(fromJson(needs.config.outputs.clients), ',') }} \
            --log-dir=$LOGNAME \
            --output result.json
      - name: Print result
        run: jq '.' result.json
      - name: Upload result to artifacts
        uses: actions/upload-artifact@v6
        with:
          name: result-aggregated
          path: result.json
      - name: Upload logs to interop.seemann.io
        uses: burnett01/rsync-deployments@33214bd98ba4ac2be90f5976672b3f030fce9ce4 # v7.1.0
        if: ${{ github.event_name == 'schedule' }}
        with:
          switches: -avzr
          path: result.json
          remote_path: ${{ vars.LOG_DIR }}/${{ needs.config.outputs.logname }}/
          remote_host: interop.seemann.io
          remote_user: ${{ secrets.INTEROP_SEEMANN_IO_USER }}
          remote_key: ${{ secrets.INTEROP_SEEMANN_IO_SSH_KEY }}
      - name: Point interop.seemann.io to the latest result
        uses: appleboy/ssh-action@0ff4204d59e8e51228ff73bce53f80d53301dee2 # v1.2.5
        if: ${{ github.event_name == 'schedule' }}
        with:
          host: interop.seemann.io
          username: ${{ secrets.INTEROP_SEEMANN_IO_USER }}
          key: ${{ secrets.INTEROP_SEEMANN_IO_SSH_KEY }}
          envs: LOGNAME
          script: |
            cd ${{ vars.LOG_DIR }}
            jq '. += [ "${{ needs.config.outputs.logname }}" ]' logs.json | sponge logs.json
            rm latest || true
            ln -s $LOGNAME latest
